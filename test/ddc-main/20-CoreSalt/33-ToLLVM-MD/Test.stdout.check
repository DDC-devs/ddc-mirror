ok
ok


-- Observable optimisations: GVN
-- Feed the output of this test to `opt -S -tbaa -basicaa -gvn -o - <test.ll>`
--
-- PROBLEM: since only load/stores can be annotated (and not function calls),
--    we have to inline addInt manually here.
--
ok
%s.Obj = type <{i64}>
@_DDC__heapBase = external global  i64
@_DDC__heapTop = external global  i64
@_DDC__heapMax = external global  i64
@_DDC__heapBackBase = external global  i64
@_DDC__heapBackTop = external global  i64
@_DDC__heapBackMax = external global  i64
declare external ccc void @abort() align 8
declare external void @llvm.gcroot(i8** , i8* )
declare external void @llvm.memcpy.p0i8.p0i8.i64(i8* , i8* , i64 , i32 , i1 )

define internal fastcc i64 @x_plus_y_square(i64*  %_v1.x, i64*  %_v2.y, i64*  %_v3.z) align 8 gc "shadow-stack"  
{
l9.entry:
        %_v10.xval1  = load i64, i64* %_v1.x,    !tbaa !7
        %_v11.yval1  = load i64, i64* %_v2.y,    !tbaa !6
        %_v12.a      = add i64 %_v10.xval1, %_v11.yval1
        store i64 %_v12.a, i64* %_v3.z,    !tbaa !8
        %_v13.xval2  = load i64, i64* %_v1.x,    !tbaa !7
        %_v14.yval2  = load i64, i64* %_v2.y,    !tbaa !6
        %_v15.b      = add i64 %_v13.xval2, %_v14.yval2
        %_v16        = mul i64 %_v12.a, %_v15.b
        ret i64 %_v16
}



!8 = !{!"x_plus_y_square_rz",  !5, i32 0}
!7 = !{!"x_plus_y_square_rx",  !6, i32 0}
!6 = !{!"x_plus_y_square_ry",  !5, i32 0}
!5 = !{!"x_plus_y_square_ROOT_4", null, i32 1}


-- Observable optimisations: GVN - constprop behaviour
ok
%s.Obj = type <{i64}>
@_DDC__heapBase = external global  i64
@_DDC__heapTop = external global  i64
@_DDC__heapMax = external global  i64
@_DDC__heapBackBase = external global  i64
@_DDC__heapBackTop = external global  i64
@_DDC__heapBackMax = external global  i64
declare external ccc void @abort() align 8
declare external void @llvm.gcroot(i8** , i8* )
declare external void @llvm.memcpy.p0i8.p0i8.i64(i8* , i8* , i64 , i32 , i1 )

define internal fastcc i64 @nothing(i64*  %_v1.x) align 8 gc "shadow-stack"  
{
l5.entry:
        ret i64 42
}

define internal fastcc i64 @three_x_plus_one(i64*  %_v7.x) align 8 gc "shadow-stack"  
{
l11.entry:
        %_v12.a      = load i64, i64* %_v7.x,    !tbaa !10
        %_v13.b      = add i64 %_v12.a, 1
        %_v15._d14   = call fastcc i64 @nothing (i64* %_v7.x) 
        %_v16.c      = load i64, i64* %_v7.x,    !tbaa !10
        %_v17.d      = mul i64 %_v16.c, 2
        %_v18        = add i64 %_v13.b, %_v17.d
        ret i64 %_v18
}



!4 = !{!"nothing_rx",  !3, i32 0}
!3 = !{!"nothing_ROOT_2", null, i32 1}
!10 = !{!"three_x_plus_one_rx",  !9, i32 1}
!9 = !{!"three_x_plus_one_ROOT_8", null, i32 1}


-- Observarble optimisations: LICM
ok
%s.Obj = type <{i64}>
@_DDC__heapBase = external global  i64
@_DDC__heapTop = external global  i64
@_DDC__heapMax = external global  i64
@_DDC__heapBackBase = external global  i64
@_DDC__heapBackTop = external global  i64
@_DDC__heapBackMax = external global  i64
declare external ccc void @abort() align 8
declare external void @llvm.gcroot(i8** , i8* )
declare external void @llvm.memcpy.p0i8.p0i8.i64(i8* , i8* , i64 , i32 , i1 )

define internal fastcc i64 @go(i64*  %_v1.a, i64*  %_v2.x, i64*  %_v3.y, i64  %_v4.i) align 8 gc "shadow-stack"  
{
l10.entry:
        switch i64 %_v4.i, label %l13.default [ i64 42,label %l11.alt ]
l11.alt:
        ret i64 %_v4.i
l13.default:
        %_v14.yval   = load i64, i64* %_v3.y,    !tbaa !9
        %_v15.yplustwo = add i64 %_v14.yval, 2
        store i64 %_v15.yplustwo, i64* %_v2.x,    !tbaa !8
        %_v17.addr   = ptrtoint i64* %_v1.a to i64
        %_v18.addr2  = add i64 %_v17.addr, %_v4.i
        %_v16.x0     = inttoptr i64 %_v18.addr2 to i64*
        store i64 %_v4.i, i64* %_v16.x0,    !tbaa !7
        %_v19.nexti  = add i64 %_v4.i, 1
        %_v20        = tail call fastcc i64 @go (i64* %_v1.a, i64* %_v2.x, i64* %_v3.y, i64 %_v19.nexti) 
        ret i64 %_v20
}



!9 = !{!"go_ry",  !6, i32 0}
!8 = !{!"go_rx",  !6, i32 0}
!7 = !{!"go_ra",  !6, i32 0}
!6 = !{!"go_ROOT_5", null, i32 1}



